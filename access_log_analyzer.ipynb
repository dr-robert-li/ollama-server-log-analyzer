{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook and script relies on the Ollama Python package and LLaMA 3 OSS LLM.\n",
    "\n",
    "To deploy this you will need to run it on a persistent server with at least 32GB of memory. Ensure that port 11434 is open.\n",
    "\n",
    "Because this python package relies on the Ollama API you may need to create a custom Client based on the server where Ollama and the model is hosted and you will need to modify the requests to Ollama below e.g:\n",
    "\n",
    "```python\n",
    "from ollama import Client\n",
    "client = Client(host='http://38.242.230.184:11434')\n",
    "\n",
    "response = client.chat(\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": prompt,\n",
    "                    }\n",
    "                ],\n",
    "                model=\"llama3\",\n",
    "            )\n",
    "```\n",
    "\n",
    "Documentation: https://github.com/ollama/ollama-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run in your terminal locally or on your persistent server if distributed before starting.\n",
    "pip install ollama\n",
    "ollama run llama3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start your python environment\n",
    "pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import gzip\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_logs(folder_path, filter_strings=None, output_folder=None):\n",
    "    log_files = []\n",
    "    for ext in [\"*.log\", \"*.gz*\"]:\n",
    "        log_files.extend(glob.glob(os.path.join(folder_path, ext)))\n",
    "\n",
    "    if not log_files:\n",
    "        print(\"No log files found in the specified folder.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(log_files)} log files in the specified folder. Log batches will be 500 lines long.\")\n",
    "\n",
    "    if filter_strings:\n",
    "        filtered_log_files = {}\n",
    "        for filter_string in filter_strings:\n",
    "            filtered_log_files[filter_string] = []\n",
    "\n",
    "        for log_file in log_files:\n",
    "            for filter_string in filter_strings:\n",
    "                if filter_string in log_file:\n",
    "                    filtered_log_files[filter_string].append(log_file)\n",
    "                    break\n",
    "\n",
    "        print(\"\\nLog files per filter:\")\n",
    "        for filter_string, log_files in filtered_log_files.items():\n",
    "            print(f\"Filter: {filter_string}, Count: {len(log_files)}\")\n",
    "\n",
    "        log_files = [log_file for log_files in filtered_log_files.values() for log_file in log_files]\n",
    "\n",
    "        if not log_files:\n",
    "            print(\"No log files match the provided filter strings.\")\n",
    "            return\n",
    "\n",
    "        print(f\"\\nTotal filtered log files: {len(log_files)}\")\n",
    "\n",
    "    output_file = os.path.join(output_folder, \"log_analysis_output.txt\")\n",
    "    with open(output_file, \"w\") as file:\n",
    "        for log_file in log_files:\n",
    "            print(f\"\\nAnalyzing log file: {log_file}\")\n",
    "            file.write(f\"\\nAnalyzing log file: {log_file}\\n\")\n",
    "            \n",
    "            if log_file.endswith(\".gz\"):\n",
    "                # Decompress gzip file\n",
    "                with gzip.open(log_file, \"rt\", encoding=\"utf-8\", errors=\"ignore\") as log_file_handle:\n",
    "                    log_lines = log_file_handle.readlines()\n",
    "            else:\n",
    "                # Read regular log file\n",
    "                with open(log_file, \"r\", encoding=\"utf-8\", errors=\"ignore\") as log_file_handle:\n",
    "                    log_lines = log_file_handle.readlines()\n",
    "            \n",
    "            batch_size = 500\n",
    "            batch_number = 1\n",
    "            total_batches = (len(log_lines) + batch_size - 1) // batch_size\n",
    "\n",
    "            for i in range(0, len(log_lines), batch_size):\n",
    "                batch = log_lines[i:i+batch_size]\n",
    "                log_content = \"\".join(batch)\n",
    "\n",
    "                print(f\"Processing batch {batch_number} of {total_batches}\")\n",
    "                file.write(f\"Processing batch {batch_number} of {total_batches}\\n\")\n",
    "\n",
    "                prompt = f\"\"\"\n",
    "                You are an expert IT systems administrator and full stack developer.\n",
    "\n",
    "                Please analyze the following log file batch for potential errors, problems, or unusual activity. \n",
    "                \n",
    "                Explain your findings.\n",
    "\n",
    "                MAKE SURE TO:\n",
    "\n",
    "                - You MUST STATE the specific request in the log VERBATIM when referencing it. My grandmother's life depends on it being stated EXACTLY as it appears in the log file.\n",
    "\n",
    "                This is an example of a specific request: \n",
    "                10.52.115.148 example.com - [19/Apr/2024:00:17:07 +0000] \"GET /wp-cron.php?doing_wp_cron HTTP/1.0\" 200 0 \"-\" \"curl/7.68.0\"\n",
    "\n",
    "                - ONLY explain findings which are unusual, abnormal, could potentially cause either security, performance, or scaling issues, are unusually long or resource intensive, repeated an unusual number of times, or potentially malicious, or otherwise suspicious. \n",
    "\n",
    "                - Here are some examples of what you should be looking for:\n",
    "\n",
    "                Excessive 404 Errors:\n",
    "                Look for a high number of requests resulting in 404 (Not Found) errors.\n",
    "                This could indicate attempts to access non-existent pages or files, which may be a sign of potential security probing or brute-force attacks.\n",
    "                \n",
    "                Unusual User Agents:\n",
    "                Pay attention to the User-Agent header in the log entries.\n",
    "                Look for suspicious or uncommon user agents that may not represent legitimate browsers or tools.\n",
    "                Malicious bots or automated scripts often use fake or modified user agents.\n",
    "                \n",
    "                Repeated Failed Login Attempts:\n",
    "                Check for a high volume of failed login attempts, especially from the same IP address or within a short timeframe.\n",
    "                This could indicate brute-force attacks trying to guess user credentials.\n",
    "                \n",
    "                Excessive Requests to Specific Pages or Resources:\n",
    "                Monitor for an unusually high number of requests to specific pages, posts, or resources.\n",
    "                This could be a sign of a denial-of-service (DoS) attack or an attempt to overwhelm the server.\n",
    "\n",
    "                Long-Running or Resource-Intensive Requests:\n",
    "                Look for requests that take an exceptionally long time to complete or consume significant server resources.\n",
    "                These requests may indicate performance issues, inefficient queries, or potential vulnerabilities.\n",
    "                \n",
    "                Suspicious Query Parameters:\n",
    "                Pay attention to the query parameters in the requested URLs.\n",
    "                Look for abnormally long or complex query strings, special characters, or attempts to inject malicious code (e.g., SQL injection, cross-site scripting).\n",
    "                \n",
    "                Unusual POST Requests or Request methods:\n",
    "                Monitor for POST requests to unusual or sensitive endpoints, such as the login page or administrative areas.\n",
    "                Look for large or suspicious payloads in the request bodies.\n",
    "                Look for unusual or suspicious HTTP request methods, such as PUT, PATCH, or DELETE.\n",
    "                \n",
    "                Repeated Requests from the Same IP Address:\n",
    "                Check for a high volume of requests originating from a single IP address within a short period.\n",
    "                This could indicate an automated script, a scraper, or an attempt to overload the server.\n",
    "                \n",
    "                Requests to Sensitive WordPress Files:\n",
    "                Look for attempts to access sensitive WordPress files directly, such as wp-config.php, xmlrpc.php, or repeated wp-login.php requests.\n",
    "                These requests may suggest attempts to exploit known vulnerabilities or gain unauthorized access.\n",
    "\n",
    "                Unusual Referrers:\n",
    "                Analyze the Referer header in the log entries.\n",
    "                Look for suspicious or unfamiliar referrers that may indicate spam or malicious links pointing to your site.\n",
    "\n",
    "                Requests with Unusual HTTP Methods:\n",
    "                Pay attention to the HTTP methods used in the requests (e.g., GET, POST, PUT, DELETE).\n",
    "                Look for requests using uncommon or unexpected HTTP methods, which may indicate attempts to exploit vulnerabilities.\n",
    "\n",
    "                Requests to Non-WordPress Directories or Files:\n",
    "                Monitor for requests to directories or files that are not part of the standard WordPress installation.\n",
    "                This could indicate attempts to access sensitive files, configuration files, or backups.\n",
    "\n",
    "                - You MUST provide specific timestamps, user agents, requests, IP addresses, or other identifying information when referencing a specific request and explaining findings.\n",
    "                - You DO NOT need to explain findings which are expected, legitimate, normal, or otherwise expected.\n",
    "                - You DO NOT need to explain the structure of the log file, the log file itself, or the log file format.\n",
    "                - You DO NOT need to provide a breakdown of each column.\n",
    "                - You DO NOT need to provide recommendations.\n",
    "                \n",
    "                This is the content of the server log:\n",
    "                \n",
    "                {log_content}\n",
    "                \"\"\"\n",
    "\n",
    "                response = ollama.chat(\n",
    "                                messages=[\n",
    "                                    {\n",
    "                                        \"role\": \"user\",\n",
    "                                        \"content\": prompt,\n",
    "                                    }\n",
    "                                ],\n",
    "                                model=\"llama3\",\n",
    "                            )\n",
    "\n",
    "                # Extract the response content from the dictionary\n",
    "                response_content = response['message']['content']\n",
    "\n",
    "                print(f\"Findings for batch {batch_number}:\")\n",
    "                print(response_content)\n",
    "                print(\"\\n\")\n",
    "\n",
    "                file.write(f\"Findings for batch {batch_number}:\\n\")\n",
    "                file.write(response_content)\n",
    "                file.write(\"\\n\\n\")\n",
    "\n",
    "                batch_number += 1\n",
    "\n",
    "    print(f\"Analysis complete. Output saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt the user for the folder path\n",
    "folder_path = input(\"Enter the folder path containing the log files: \")\n",
    "\n",
    "# Prompt the user for multiple filter strings\n",
    "filter_strings = input(\"Enter filter strings separated by commas (optional): \").split(\",\")\n",
    "filter_strings = [s.strip() for s in filter_strings if s.strip()]\n",
    "if not filter_strings:\n",
    "    filter_strings = None\n",
    "\n",
    "# Prompt the user for the output folder\n",
    "output_folder = input(\"Enter the folder path to save the output text file: \")\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to analyze the log files\n",
    "analyze_logs(folder_path, filter_strings, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the output text file\n",
    "output_file = os.path.join(output_folder, \"log_analysis_output.txt\")\n",
    "with open(output_file, \"r\") as file:\n",
    "    output_lines = file.readlines()\n",
    "\n",
    "# Batch the output lines into 1000 lines per batch\n",
    "batch_size = 1000\n",
    "batch_summaries = []\n",
    "\n",
    "for i in range(0, len(output_lines), batch_size):\n",
    "    batch = output_lines[i:i+batch_size]\n",
    "    batch_content = \"\".join(batch)\n",
    "\n",
    "    # Generate a summary of each batch using ollama.chat\n",
    "    prompt = f\"\"\"\n",
    "        Please provide a summary of the entire following log analysis output.\n",
    "\n",
    "        Provide 1 summary of all batches of log analysis, together.\n",
    "\n",
    "        Here is the log analysis output:\\n\\n{batch_content}\n",
    "        \"\"\"\n",
    "\n",
    "    response = ollama.chat(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "        model=\"llama3\",\n",
    "    )\n",
    "\n",
    "    # Extract the response content from the dictionary\n",
    "    batch_summary = response['message']['content']\n",
    "    batch_summaries.append(batch_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate the batch summaries\n",
    "aggregated_summary = \"\\n\".join(batch_summaries)\n",
    "\n",
    "# Generate a summary of the aggregated summaries using ollama.chat\n",
    "prompt = f\"Please provide a summary of the following aggregated log analysis summaries:\\n\\n{aggregated_summary}\"\n",
    "\n",
    "response = ollama.chat(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama3\",\n",
    ")\n",
    "\n",
    "# Extract the response content from the dictionary\n",
    "final_summary = response['message']['content']\n",
    "\n",
    "print(\"Summary of the aggregated log analysis summaries:\")\n",
    "print(final_summary)\n",
    "\n",
    "# Save the final summary to a text file in the output folder\n",
    "final_summary_file = os.path.join(output_folder, \"log_analysis_summary.txt\")\n",
    "with open(final_summary_file, \"w\") as file:\n",
    "    file.write(final_summary)\n",
    "\n",
    "print(f\"Final summary saved to: {final_summary_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
